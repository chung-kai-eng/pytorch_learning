{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5ded49-ce55-4b90-95d9-b78de9058785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DALab\\Documents\\GitHub\\pytorch_learning\\Variational AutoEncoder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from tensorboardX import SummaryWriter\n",
    "print(os.getcwd())\n",
    "torch.__version__\n",
    "# \"\\Colab Notebooks\\dataset\\X_modify.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f475efc6-d4c7-41f7-b9c1-9386a74f0ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "# torch.cuda.set_device(1) # set pytorch run\n",
    "device = torch.device('cuda' if CUDA else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95c6d3-8c7f-41c3-b735-892c8d324b4e",
   "metadata": {},
   "source": [
    "### SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13952dc6-863c-4e2e-b9f8-d16330c9c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# define the path that store log information\n",
    "LOG_DIR = './logs/' + dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "writer = SummaryWriter(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "405789af-6f3c-4f20-8b68-062fe8793ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter setting\n",
    "image_size = 28\n",
    "# h_dim = 400\n",
    "# z_dim = 20\n",
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea395195-98fa-4c15-962f-109a22359a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(root='./dataset/minist',\n",
    "                    train=True,\n",
    "                    transform=transforms.ToTensor(),\n",
    "                    download=True)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                      batch_size=batch_size, \n",
    "                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b75edf49-4a30-47c7-9f0d-56e13cc589c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "inputs, classes = next(iter(data_loader))   \n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9657bdad-4763-495a-a751-eee13005a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(inputs)\n",
    "writer.add_image(\"images\", grid)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cdbe41-de5d-4e7d-8800-77a66ee706c0",
   "metadata": {},
   "source": [
    "### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dee3650-3fb7-42f3-9905-1aabb87ec52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1) # (in_channels, out_channels, kernel_size)\n",
    "        self.batchnorm = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=0) \n",
    "        self.batchnorm2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=0)\n",
    "        self.linear1 = nn.Linear(32*6*6, 128)\n",
    "        self.linear2 = nn.Linear(128, latent_dim) # for mean \n",
    "        self.linear3 = nn.Linear(128, latent_dim) # for variance\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.batchnorm(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.batchnorm2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # print('final convolution: ', x.shape)\n",
    "        x = torch.flatten(x, start_dim=1) \n",
    "        # print('after flatten: ', x.shape)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        # print(x.shape)\n",
    "        mu = self.linear2(x)\n",
    "        # print(mu.shape)\n",
    "        log_var = self.linear3(x)\n",
    "        # print(mu)\n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear4 = nn.Linear(latent_dim, 128)\n",
    "        self.linear5 = nn.Linear(128, 32*6*6)\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=torch.Size([32, 6, 6])) # torch.Size(3*3*32)   (32, 6, 6)\n",
    "        self.deconvolution1 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, output_padding=0) # padding versus output_padding\n",
    "        self.batchnorm3 = nn.BatchNorm2d(16)\n",
    "        self.deconvolution2 = nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, output_padding=1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(8)\n",
    "        self.deconvolution3 = nn.ConvTranspose2d(8, 1, kernel_size=1, stride=1, output_padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # linear layer\n",
    "        x = F.relu(self.linear4(x))\n",
    "        x = F.relu(self.linear5(x))\n",
    "        # print('before unflatten: ', x.shape)\n",
    "        # x = self.unflatten(x)\n",
    "        x = x.view(-1, 32, 6, 6)\n",
    "        # print('unflatten: ', x.shape)\n",
    "        # deconvolution layer\n",
    "        x = self.deconvolution1(x)\n",
    "        x = F.relu(self.batchnorm3(x))\n",
    "        x = self.deconvolution2(x)\n",
    "        x = F.relu(self.batchnorm4(x))\n",
    "        x = self.deconvolution3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class VAE(nn.Module): # for image input data\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        # check how to use distribution on the GPU device\n",
    "        self.Normal_dist = torch.distributions.Normal(0, 1)      # for reparameterization     \n",
    "        # self.Normal_dist.loc = self.Normal_dist.loc.cuda()     # if running on the GPU, uncomment these two lines\n",
    "        # self.Normal_dist.scale = self.Normal_dist.scale.cuda()   \n",
    "        self.decoder = Decoder(latent_dim)\n",
    "        # compute KL divergence or other metrics\n",
    "        self.loss = 0\n",
    "\n",
    "    # pathwise derivative estimator is commonly seen in the reparameterization trick (also used a lot in reinforcement learning)\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        # compute sample z as the latent vector\n",
    "        std = torch.exp(log_var/2)\n",
    "        # z = mu + std * self.Normal_dist(mu.shape)\n",
    "        z = mu + std * self.Normal_dist.sample(mu.shape)\n",
    "        # print('z type: ', z.is_cuda)\n",
    "        return z\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "\n",
    "        output = self.decoder(z)\n",
    "        # (optional) non-linear mapping for the last layer\n",
    "        output = F.relu(output)\n",
    "        return output, mu, log_var\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea949497-dfc0-4d4d-8921-dd23559ca8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(latent_dim=40)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "090023d3-2557-4175-b302-7d07270d7061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Encoder(\n",
      "    (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batchnorm): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (batchnorm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (linear1): Linear(in_features=1152, out_features=128, bias=True)\n",
      "    (linear2): Linear(in_features=128, out_features=40, bias=True)\n",
      "    (linear3): Linear(in_features=128, out_features=40, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (linear4): Linear(in_features=40, out_features=128, bias=True)\n",
      "    (linear5): Linear(in_features=128, out_features=1152, bias=True)\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=torch.Size([32, 6, 6]))\n",
      "    (deconvolution1): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (batchnorm3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (deconvolution2): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), output_padding=(1, 1))\n",
      "    (batchnorm4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (deconvolution3): ConvTranspose2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b970225-f548-4335-8067-845d168ecc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [1, 8, 28, 28]              80\n",
      "       BatchNorm2d-2             [1, 8, 28, 28]              16\n",
      "            Conv2d-3            [1, 16, 13, 13]           1,168\n",
      "       BatchNorm2d-4            [1, 16, 13, 13]              32\n",
      "            Conv2d-5              [1, 32, 6, 6]           4,640\n",
      "            Linear-6                   [1, 128]         147,584\n",
      "            Linear-7                    [1, 40]           5,160\n",
      "            Linear-8                    [1, 40]           5,160\n",
      "           Encoder-9       [[-1, 40], [-1, 40]]               0\n",
      "           Linear-10                   [1, 128]           5,248\n",
      "           Linear-11                  [1, 1152]         148,608\n",
      "  ConvTranspose2d-12            [1, 16, 13, 13]           4,624\n",
      "      BatchNorm2d-13            [1, 16, 13, 13]              32\n",
      "  ConvTranspose2d-14             [1, 8, 28, 28]           1,160\n",
      "      BatchNorm2d-15             [1, 8, 28, 28]              16\n",
      "  ConvTranspose2d-16             [1, 1, 28, 28]               9\n",
      "          Decoder-17             [1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 323,537\n",
      "Trainable params: 323,537\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.32\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 1.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "input_size = (1, 28, 28)\n",
    "if CUDA:\n",
    "    summary(model.cuda(), input_size, batch_size=1) #, device='cuda'\n",
    "else:\n",
    "    summary(model, input_size, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b559f-8ac0-4f65-9897-2a311249526a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d23cb981-d00d-4c82-abb2-b9881dddbbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/3], Step [100/469], Reconst Loss: 0.0981\n",
      "Epoch[1/3], Step [200/469], Reconst Loss: 0.0977\n",
      "Epoch[1/3], Step [300/469], Reconst Loss: 0.0949\n",
      "Epoch[1/3], Step [400/469], Reconst Loss: 0.1006\n",
      "Epoch[2/3], Step [100/469], Reconst Loss: 0.0997\n",
      "Epoch[2/3], Step [200/469], Reconst Loss: 0.1005\n",
      "Epoch[2/3], Step [300/469], Reconst Loss: 0.1024\n",
      "Epoch[2/3], Step [400/469], Reconst Loss: 0.1012\n",
      "Epoch[3/3], Step [100/469], Reconst Loss: 0.1038\n",
      "Epoch[3/3], Step [200/469], Reconst Loss: 0.0952\n",
      "Epoch[3/3], Step [300/469], Reconst Loss: 0.0986\n",
      "Epoch[3/3], Step [400/469], Reconst Loss: 0.0932\n"
     ]
    }
   ],
   "source": [
    "def train_per_epoch(train_loader=None, model=None, loss_fn=None, optimizer=None, show_pred_result=False):\n",
    "    def loss_fn(input, output, mu, log_var, criterion):\n",
    "        # print(f'{mu}, {log_var}')\n",
    "        mse = criterion(input, output)\n",
    "        kl_element = mu.pow(2).add_(log_var.exp()).mul_(-1).add_(1).add_(log_var)\n",
    "        kl = torch.sum(kl_element).mul_(-0.5)\n",
    "        # kl_divergence = 0.5*torch.sum(-1-log_var+mu**2+log_var.exp())\n",
    "        # print(kl_divergence)\n",
    "        # return F.binary_cross_entropy(input, output, size_average=False) + kl_divergence\n",
    "        return mse + kl\n",
    "\n",
    "    # for one epoch, multiple batches\n",
    "    model.train()   # assure Dropout, BatchNormalization... layers open in training step\n",
    "    \n",
    "    train_loss = 0\n",
    "    true_rlt = []\n",
    "    pred_rlt = []\n",
    "\n",
    "    for i, (data, label) in enumerate(train_loader):\n",
    "        if CUDA:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "\n",
    "        # ============= forward ===============\n",
    "        output, mu, log_var = model(data)\n",
    "        # loss_fn.cuda()  # if loss function have parameter, we need to add .cuda\n",
    "        loss = loss_fn(data, output, mu, log_var, criterion=nn.MSELoss())\n",
    "        train_loss += loss\n",
    "\n",
    "        # ============= backward ===============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        writer.add_scalar('Loss/train', loss/100, epoch*len(train_loader)+i)\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}\" \n",
    "                .format(epoch+1, num_epochs, i+1, len(data_loader), loss))\n",
    "            \n",
    "        if i % 10 == 0:\n",
    "            for name, param in model.named_parameters():\n",
    "                writer.add_histogram(name, param.clone().cpu().data.numpy(), i)\n",
    "    return train_loss \n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    train_per_epoch(data_loader, model, loss_fn=None, optimizer=optimizer, show_pred_result=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41a58199-da2b-4c66-98a5-bdaca5fe2766",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74819ac0-e769-41ea-a469-16462556d6e1",
   "metadata": {},
   "source": [
    "```cd <dir>```\n",
    "\n",
    "```tensorboard --logdir logs```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c3a76-b30d-474e-acd5-bef87c3492a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9bb0d-8eb3-41d2-bb91-dd9deda284df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
